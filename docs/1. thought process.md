# 1. Thought Process

## Time Management Strategy

When I first received the briefing for this project, my immediate thought was: **"How do I manage my time effectively because I want to respect the 4-hour limit and also consider it as a challenge to myself to only do it in 4 hours?"**

This time constraint became a key driver in my decision-making process throughout the project.

### Learning Phase (45 minutes)

The first thing I did was spend a good amount of time, maybe 45 minutes, just reading about KServe, doing some tutorials, so that I could get a hang of what I need to do. This was crucial because:

- KServe was the part of the project I was most unfamiliar with
- Understanding the infrastructure requirements upfront would prevent costly mistakes later
- Getting the protocol right from the start would save time on debugging

### Build-First Approach

The second key decision I made was: **"I'm rather going to build a simple version of this workflow end-to-end and iterate from there."**

This approach was chosen because:
- If I can get a simple version working end-to-end, then it would be quite easy for me to iterate on the data science side of things
- I'm comfortable improving my data science approach once the infrastructure/docker/complete workflow is in place


## Data Science Solution Trade-offs

When thinking about how to solve the data science part of this project, I recognized there are many ways to approach name classification. My first thought was that an LLM could easily do this, but then I thought: **"Is there not a cheaper way to do this? You probably don't want to incur cost unnecessarily if you're doing this in production."**

I identified several key trade-offs to consider:

### 1. Complexity of the Solution
- Simple solutions are easier to implement and debug
- Complex solutions may offer better performance but require more development time
- Given the 4-hour constraint, complexity becomes a significant factor

### 2. Cost of the Solution
- API calls to external services have ongoing costs
- Self-hosted solutions have infrastructure costs
- Training custom models has computational costs

### 3. Performance of the Model
- Accuracy vs speed trade-offs
- False positive/negative rates
- Confidence scoring capabilities

## Solution Options Considered

With these trade-offs in mind, I came up with several approaches to solve the name classification problem:

### 1. LLM API Approach (e.g., GPT-4o-mini)
**Pros:**
- Very easy to implement
- High accuracy out of the box
- Fast development time
- Good for experimentation

**Cons:**
- Ongoing API costs
- External dependency

### 2. Traditional NLP (NLTK)
**Pros:**
- Free to use
- No external dependencies
- Good for named entity recognition
- Well-established library

**Cons:**
- Limited customisation options
- Potentially lower accuracy for this specific use case

### 3. Regex-Based Approach
**Pros:**
- Very fast
- No external dependencies
- Complete control over logic
- Easy to understand and debug

**Cons:**
- High risk of false negatives and false positives
- Company names and people's names can be quite similar
- Brittle to edge cases


### 4. Fine-tuned Small Language Model
**Pros:**
- Can be optimised for this specific task
- Good balance of performance and cost
- No ongoing API costs once trained
- Can be deployed locally

**Cons:**
- Requires training time and data
- More complex infrastructure
- Higher initial development time

### 5. Open Source Solutions (Existing GitHub Repos)
**Pros:**
- Leverage existing work
- Often well-tested and documented
- Community support
- Can be customised

**Cons:**
- May not fit exact requirements
- Dependency on external projects
- Potential licensing issues
- May require significant adaptation

### 6. Hybrid Feature Engineering + Traditional ML (Chosen Approach)
**Pros:**
- No ongoing API costs
- Fast inference on CPU-only hardware
- Demonstrates ML fundamentals
- Full control over features and model
- Easy to iterate and improve
- Fits within resource constraints

**Cons:**
- Requires more upfront development time
- Needs domain knowledge for feature engineering
- May not match LLM accuracy initially
- Requires training data preparation

## Decision Framework

Given the 4-hour time constraint and the need to build an end-to-end system, I prioritised:

1. **Speed of implementation** - Get something working quickly
2. **End-to-end functionality** - Ensure the complete pipeline works
3. **Iteration capability** - Make it easy to improve the ML component later
4. **Production readiness** - Build with deployment in mind

## Final Decision

After evaluating all options, I chose **Option 6: Hybrid Feature Engineering + Random Forest Classifier**

This approach wasn't initially listed because I designed it specifically to balance all trade-offs:

**Why this choice:**
- **No ongoing API costs** - Unlike LLM APIs, runs entirely locally
- **Fast inference** - <10ms per prediction on CPU-only hardware
- **Moderate complexity** - Can be built within 4-hour constraint
- **Demonstrates ML expertise** - Shows understanding of feature engineering, model selection, and evaluation
- **Iterative improvement** - Easy to add more features or swap models later
- **Production-ready** - Fits within 1 vCPU, 2GB RAM, and 6GB container constraints

While an LLM API (e.g., GPT-4o-mini) would achieve high accuracy with minimal code, it doesn't demonstrate machine learning fundamentals and incurs ongoing costs. The hybrid feature engineering approach shows deeper technical understanding whilst remaining practical for production deployment.

**Next:** See `2. modelling approach.md` for detailed implementation!